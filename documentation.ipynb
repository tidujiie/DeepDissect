{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dissect: Ablation Studies with MMDetection Models\n",
    "\n",
    "## Introduction\n",
    "Ablation studies are critical for understanding the impact of various components and configurations in deep learning models. In the context of object detection, evaluating different architectural choices and hyperparameters can significantly affect model performance.\n",
    "\n",
    "## MMDetection: A Quick Overview\n",
    "[MMDetection](https://github.com/open-mmlab/mmdetection) is an open-source object detection toolbox based on PyTorch. It provides a flexible platform for benchmarking and developing state-of-the-art detection models, including but not limited to, Faster R-CNN, Mask R-CNN, and DETR.\n",
    "\n",
    "## Deep Dissect: Ablation Studies Library for MMDetection\n",
    "The ablation studies library for MMDetection models is designed to facilitate systematic experimentation and evaluation of different model components. By allowing researchers and practitioners to easily toggle and modify parts of their models, the library aids in understanding each component's contribution to the overall performance.\n",
    "\n",
    "### Features\n",
    "- **Single Unit Ablations:** Isolate and evaluate single units inside a component.\n",
    "- **Attention-head Ablations:** Isolate and evaluate complete attention heads inside a component.\n",
    "- **Component Ablations:** Isolate and evaluate the impact of individual model components.\n",
    "- **Layer Ablations:** Isolate and evaluate the impact of selected layers.\n",
    "\n",
    "## Applying Deep Dissect on MMDetection Models\n",
    "To conduct an ablation study on a MMDetection model using the library, follow these general steps:\n",
    "\n",
    "1. **Select Model:** Select a Model you wish to study.\n",
    "\n",
    "2. **Select Ablation Algorithm:** Identify which component of a MMDetection model you wish to study, such as encoder, decoder layers, query embeddings, attention heads or anything else.\n",
    "\n",
    "3. **Evaluate the Results:** Execute the ablation studies, ensuring to track the performance impacts of each variation.\n",
    "\n",
    "## Examples for each Function\n",
    "This notebook represents examples for each function of the library"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from deep_dissect import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the checkpoint file for identifying the names of the component of a checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_preprocessor.mean', 'data_preprocessor.std', 'backbone.conv1.weight', 'backbone.bn1.weight', 'backbone.bn1.bias', 'backbone.bn1.running_mean', 'backbone.bn1.running_var', 'backbone.bn1.num_batches_tracked', 'backbone.layer1.0.conv1.weight', 'backbone.layer1.0.bn1.weight', 'backbone.layer1.0.bn1.bias', 'backbone.layer1.0.bn1.running_mean', 'backbone.layer1.0.bn1.running_var', 'backbone.layer1.0.bn1.num_batches_tracked', 'backbone.layer1.0.conv2.weight', 'backbone.layer1.0.bn2.weight', 'backbone.layer1.0.bn2.bias', 'backbone.layer1.0.bn2.running_mean', 'backbone.layer1.0.bn2.running_var', 'backbone.layer1.0.bn2.num_batches_tracked', 'backbone.layer1.0.conv3.weight', 'backbone.layer1.0.bn3.weight', 'backbone.layer1.0.bn3.bias', 'backbone.layer1.0.bn3.running_mean', 'backbone.layer1.0.bn3.running_var', 'backbone.layer1.0.bn3.num_batches_tracked', 'backbone.layer1.0.downsample.0.weight', 'backbone.layer1.0.downsample.1.weight', 'backbone.layer1.0.downsample.1.bias', 'backbone.layer1.0.downsample.1.running_mean', 'backbone.layer1.0.downsample.1.running_var', 'backbone.layer1.0.downsample.1.num_batches_tracked', 'backbone.layer1.1.conv1.weight', 'backbone.layer1.1.bn1.weight', 'backbone.layer1.1.bn1.bias', 'backbone.layer1.1.bn1.running_mean', 'backbone.layer1.1.bn1.running_var', 'backbone.layer1.1.bn1.num_batches_tracked', 'backbone.layer1.1.conv2.weight', 'backbone.layer1.1.bn2.weight', 'backbone.layer1.1.bn2.bias', 'backbone.layer1.1.bn2.running_mean', 'backbone.layer1.1.bn2.running_var', 'backbone.layer1.1.bn2.num_batches_tracked', 'backbone.layer1.1.conv3.weight', 'backbone.layer1.1.bn3.weight', 'backbone.layer1.1.bn3.bias', 'backbone.layer1.1.bn3.running_mean', 'backbone.layer1.1.bn3.running_var', 'backbone.layer1.1.bn3.num_batches_tracked', 'backbone.layer1.2.conv1.weight', 'backbone.layer1.2.bn1.weight', 'backbone.layer1.2.bn1.bias', 'backbone.layer1.2.bn1.running_mean', 'backbone.layer1.2.bn1.running_var', 'backbone.layer1.2.bn1.num_batches_tracked', 'backbone.layer1.2.conv2.weight', 'backbone.layer1.2.bn2.weight', 'backbone.layer1.2.bn2.bias', 'backbone.layer1.2.bn2.running_mean', 'backbone.layer1.2.bn2.running_var', 'backbone.layer1.2.bn2.num_batches_tracked', 'backbone.layer1.2.conv3.weight', 'backbone.layer1.2.bn3.weight', 'backbone.layer1.2.bn3.bias', 'backbone.layer1.2.bn3.running_mean', 'backbone.layer1.2.bn3.running_var', 'backbone.layer1.2.bn3.num_batches_tracked', 'backbone.layer2.0.conv1.weight', 'backbone.layer2.0.bn1.weight', 'backbone.layer2.0.bn1.bias', 'backbone.layer2.0.bn1.running_mean', 'backbone.layer2.0.bn1.running_var', 'backbone.layer2.0.bn1.num_batches_tracked', 'backbone.layer2.0.conv2.weight', 'backbone.layer2.0.bn2.weight', 'backbone.layer2.0.bn2.bias', 'backbone.layer2.0.bn2.running_mean', 'backbone.layer2.0.bn2.running_var', 'backbone.layer2.0.bn2.num_batches_tracked', 'backbone.layer2.0.conv3.weight', 'backbone.layer2.0.bn3.weight', 'backbone.layer2.0.bn3.bias', 'backbone.layer2.0.bn3.running_mean', 'backbone.layer2.0.bn3.running_var', 'backbone.layer2.0.bn3.num_batches_tracked', 'backbone.layer2.0.downsample.0.weight', 'backbone.layer2.0.downsample.1.weight', 'backbone.layer2.0.downsample.1.bias', 'backbone.layer2.0.downsample.1.running_mean', 'backbone.layer2.0.downsample.1.running_var', 'backbone.layer2.0.downsample.1.num_batches_tracked', 'backbone.layer2.1.conv1.weight', 'backbone.layer2.1.bn1.weight', 'backbone.layer2.1.bn1.bias', 'backbone.layer2.1.bn1.running_mean', 'backbone.layer2.1.bn1.running_var', 'backbone.layer2.1.bn1.num_batches_tracked', 'backbone.layer2.1.conv2.weight', 'backbone.layer2.1.bn2.weight', 'backbone.layer2.1.bn2.bias', 'backbone.layer2.1.bn2.running_mean', 'backbone.layer2.1.bn2.running_var', 'backbone.layer2.1.bn2.num_batches_tracked', 'backbone.layer2.1.conv3.weight', 'backbone.layer2.1.bn3.weight', 'backbone.layer2.1.bn3.bias', 'backbone.layer2.1.bn3.running_mean', 'backbone.layer2.1.bn3.running_var', 'backbone.layer2.1.bn3.num_batches_tracked', 'backbone.layer2.2.conv1.weight', 'backbone.layer2.2.bn1.weight', 'backbone.layer2.2.bn1.bias', 'backbone.layer2.2.bn1.running_mean', 'backbone.layer2.2.bn1.running_var', 'backbone.layer2.2.bn1.num_batches_tracked', 'backbone.layer2.2.conv2.weight', 'backbone.layer2.2.bn2.weight', 'backbone.layer2.2.bn2.bias', 'backbone.layer2.2.bn2.running_mean', 'backbone.layer2.2.bn2.running_var', 'backbone.layer2.2.bn2.num_batches_tracked', 'backbone.layer2.2.conv3.weight', 'backbone.layer2.2.bn3.weight', 'backbone.layer2.2.bn3.bias', 'backbone.layer2.2.bn3.running_mean', 'backbone.layer2.2.bn3.running_var', 'backbone.layer2.2.bn3.num_batches_tracked', 'backbone.layer2.3.conv1.weight', 'backbone.layer2.3.bn1.weight', 'backbone.layer2.3.bn1.bias', 'backbone.layer2.3.bn1.running_mean', 'backbone.layer2.3.bn1.running_var', 'backbone.layer2.3.bn1.num_batches_tracked', 'backbone.layer2.3.conv2.weight', 'backbone.layer2.3.bn2.weight', 'backbone.layer2.3.bn2.bias', 'backbone.layer2.3.bn2.running_mean', 'backbone.layer2.3.bn2.running_var', 'backbone.layer2.3.bn2.num_batches_tracked', 'backbone.layer2.3.conv3.weight', 'backbone.layer2.3.bn3.weight', 'backbone.layer2.3.bn3.bias', 'backbone.layer2.3.bn3.running_mean', 'backbone.layer2.3.bn3.running_var', 'backbone.layer2.3.bn3.num_batches_tracked', 'backbone.layer3.0.conv1.weight', 'backbone.layer3.0.bn1.weight', 'backbone.layer3.0.bn1.bias', 'backbone.layer3.0.bn1.running_mean', 'backbone.layer3.0.bn1.running_var', 'backbone.layer3.0.bn1.num_batches_tracked', 'backbone.layer3.0.conv2.weight', 'backbone.layer3.0.bn2.weight', 'backbone.layer3.0.bn2.bias', 'backbone.layer3.0.bn2.running_mean', 'backbone.layer3.0.bn2.running_var', 'backbone.layer3.0.bn2.num_batches_tracked', 'backbone.layer3.0.conv3.weight', 'backbone.layer3.0.bn3.weight', 'backbone.layer3.0.bn3.bias', 'backbone.layer3.0.bn3.running_mean', 'backbone.layer3.0.bn3.running_var', 'backbone.layer3.0.bn3.num_batches_tracked', 'backbone.layer3.0.downsample.0.weight', 'backbone.layer3.0.downsample.1.weight', 'backbone.layer3.0.downsample.1.bias', 'backbone.layer3.0.downsample.1.running_mean', 'backbone.layer3.0.downsample.1.running_var', 'backbone.layer3.0.downsample.1.num_batches_tracked', 'backbone.layer3.1.conv1.weight', 'backbone.layer3.1.bn1.weight', 'backbone.layer3.1.bn1.bias', 'backbone.layer3.1.bn1.running_mean', 'backbone.layer3.1.bn1.running_var', 'backbone.layer3.1.bn1.num_batches_tracked', 'backbone.layer3.1.conv2.weight', 'backbone.layer3.1.bn2.weight', 'backbone.layer3.1.bn2.bias', 'backbone.layer3.1.bn2.running_mean', 'backbone.layer3.1.bn2.running_var', 'backbone.layer3.1.bn2.num_batches_tracked', 'backbone.layer3.1.conv3.weight', 'backbone.layer3.1.bn3.weight', 'backbone.layer3.1.bn3.bias', 'backbone.layer3.1.bn3.running_mean', 'backbone.layer3.1.bn3.running_var', 'backbone.layer3.1.bn3.num_batches_tracked', 'backbone.layer3.2.conv1.weight', 'backbone.layer3.2.bn1.weight', 'backbone.layer3.2.bn1.bias', 'backbone.layer3.2.bn1.running_mean', 'backbone.layer3.2.bn1.running_var', 'backbone.layer3.2.bn1.num_batches_tracked', 'backbone.layer3.2.conv2.weight', 'backbone.layer3.2.bn2.weight', 'backbone.layer3.2.bn2.bias', 'backbone.layer3.2.bn2.running_mean', 'backbone.layer3.2.bn2.running_var', 'backbone.layer3.2.bn2.num_batches_tracked', 'backbone.layer3.2.conv3.weight', 'backbone.layer3.2.bn3.weight', 'backbone.layer3.2.bn3.bias', 'backbone.layer3.2.bn3.running_mean', 'backbone.layer3.2.bn3.running_var', 'backbone.layer3.2.bn3.num_batches_tracked', 'backbone.layer3.3.conv1.weight', 'backbone.layer3.3.bn1.weight', 'backbone.layer3.3.bn1.bias', 'backbone.layer3.3.bn1.running_mean', 'backbone.layer3.3.bn1.running_var', 'backbone.layer3.3.bn1.num_batches_tracked', 'backbone.layer3.3.conv2.weight', 'backbone.layer3.3.bn2.weight', 'backbone.layer3.3.bn2.bias', 'backbone.layer3.3.bn2.running_mean', 'backbone.layer3.3.bn2.running_var', 'backbone.layer3.3.bn2.num_batches_tracked', 'backbone.layer3.3.conv3.weight', 'backbone.layer3.3.bn3.weight', 'backbone.layer3.3.bn3.bias', 'backbone.layer3.3.bn3.running_mean', 'backbone.layer3.3.bn3.running_var', 'backbone.layer3.3.bn3.num_batches_tracked', 'backbone.layer3.4.conv1.weight', 'backbone.layer3.4.bn1.weight', 'backbone.layer3.4.bn1.bias', 'backbone.layer3.4.bn1.running_mean', 'backbone.layer3.4.bn1.running_var', 'backbone.layer3.4.bn1.num_batches_tracked', 'backbone.layer3.4.conv2.weight', 'backbone.layer3.4.bn2.weight', 'backbone.layer3.4.bn2.bias', 'backbone.layer3.4.bn2.running_mean', 'backbone.layer3.4.bn2.running_var', 'backbone.layer3.4.bn2.num_batches_tracked', 'backbone.layer3.4.conv3.weight', 'backbone.layer3.4.bn3.weight', 'backbone.layer3.4.bn3.bias', 'backbone.layer3.4.bn3.running_mean', 'backbone.layer3.4.bn3.running_var', 'backbone.layer3.4.bn3.num_batches_tracked', 'backbone.layer3.5.conv1.weight', 'backbone.layer3.5.bn1.weight', 'backbone.layer3.5.bn1.bias', 'backbone.layer3.5.bn1.running_mean', 'backbone.layer3.5.bn1.running_var', 'backbone.layer3.5.bn1.num_batches_tracked', 'backbone.layer3.5.conv2.weight', 'backbone.layer3.5.bn2.weight', 'backbone.layer3.5.bn2.bias', 'backbone.layer3.5.bn2.running_mean', 'backbone.layer3.5.bn2.running_var', 'backbone.layer3.5.bn2.num_batches_tracked', 'backbone.layer3.5.conv3.weight', 'backbone.layer3.5.bn3.weight', 'backbone.layer3.5.bn3.bias', 'backbone.layer3.5.bn3.running_mean', 'backbone.layer3.5.bn3.running_var', 'backbone.layer3.5.bn3.num_batches_tracked', 'backbone.layer4.0.conv1.weight', 'backbone.layer4.0.bn1.weight', 'backbone.layer4.0.bn1.bias', 'backbone.layer4.0.bn1.running_mean', 'backbone.layer4.0.bn1.running_var', 'backbone.layer4.0.bn1.num_batches_tracked', 'backbone.layer4.0.conv2.weight', 'backbone.layer4.0.bn2.weight', 'backbone.layer4.0.bn2.bias', 'backbone.layer4.0.bn2.running_mean', 'backbone.layer4.0.bn2.running_var', 'backbone.layer4.0.bn2.num_batches_tracked', 'backbone.layer4.0.conv3.weight', 'backbone.layer4.0.bn3.weight', 'backbone.layer4.0.bn3.bias', 'backbone.layer4.0.bn3.running_mean', 'backbone.layer4.0.bn3.running_var', 'backbone.layer4.0.bn3.num_batches_tracked', 'backbone.layer4.0.downsample.0.weight', 'backbone.layer4.0.downsample.1.weight', 'backbone.layer4.0.downsample.1.bias', 'backbone.layer4.0.downsample.1.running_mean', 'backbone.layer4.0.downsample.1.running_var', 'backbone.layer4.0.downsample.1.num_batches_tracked', 'backbone.layer4.1.conv1.weight', 'backbone.layer4.1.bn1.weight', 'backbone.layer4.1.bn1.bias', 'backbone.layer4.1.bn1.running_mean', 'backbone.layer4.1.bn1.running_var', 'backbone.layer4.1.bn1.num_batches_tracked', 'backbone.layer4.1.conv2.weight', 'backbone.layer4.1.bn2.weight', 'backbone.layer4.1.bn2.bias', 'backbone.layer4.1.bn2.running_mean', 'backbone.layer4.1.bn2.running_var', 'backbone.layer4.1.bn2.num_batches_tracked', 'backbone.layer4.1.conv3.weight', 'backbone.layer4.1.bn3.weight', 'backbone.layer4.1.bn3.bias', 'backbone.layer4.1.bn3.running_mean', 'backbone.layer4.1.bn3.running_var', 'backbone.layer4.1.bn3.num_batches_tracked', 'backbone.layer4.2.conv1.weight', 'backbone.layer4.2.bn1.weight', 'backbone.layer4.2.bn1.bias', 'backbone.layer4.2.bn1.running_mean', 'backbone.layer4.2.bn1.running_var', 'backbone.layer4.2.bn1.num_batches_tracked', 'backbone.layer4.2.conv2.weight', 'backbone.layer4.2.bn2.weight', 'backbone.layer4.2.bn2.bias', 'backbone.layer4.2.bn2.running_mean', 'backbone.layer4.2.bn2.running_var', 'backbone.layer4.2.bn2.num_batches_tracked', 'backbone.layer4.2.conv3.weight', 'backbone.layer4.2.bn3.weight', 'backbone.layer4.2.bn3.bias', 'backbone.layer4.2.bn3.running_mean', 'backbone.layer4.2.bn3.running_var', 'backbone.layer4.2.bn3.num_batches_tracked', 'neck.convs.0.conv.weight', 'neck.convs.0.conv.bias', 'bbox_head.fc_cls.weight', 'bbox_head.fc_cls.bias', 'bbox_head.reg_ffn.layers.0.0.weight', 'bbox_head.reg_ffn.layers.0.0.bias', 'bbox_head.reg_ffn.layers.1.weight', 'bbox_head.reg_ffn.layers.1.bias', 'bbox_head.fc_reg.weight', 'bbox_head.fc_reg.bias', 'encoder.layers.0.self_attn.attn.in_proj_weight', 'encoder.layers.0.self_attn.attn.in_proj_bias', 'encoder.layers.0.self_attn.attn.out_proj.weight', 'encoder.layers.0.self_attn.attn.out_proj.bias', 'encoder.layers.0.ffn.layers.0.0.weight', 'encoder.layers.0.ffn.layers.0.0.bias', 'encoder.layers.0.ffn.layers.1.weight', 'encoder.layers.0.ffn.layers.1.bias', 'encoder.layers.0.norms.0.weight', 'encoder.layers.0.norms.0.bias', 'encoder.layers.0.norms.1.weight', 'encoder.layers.0.norms.1.bias', 'encoder.layers.1.self_attn.attn.in_proj_weight', 'encoder.layers.1.self_attn.attn.in_proj_bias', 'encoder.layers.1.self_attn.attn.out_proj.weight', 'encoder.layers.1.self_attn.attn.out_proj.bias', 'encoder.layers.1.ffn.layers.0.0.weight', 'encoder.layers.1.ffn.layers.0.0.bias', 'encoder.layers.1.ffn.layers.1.weight', 'encoder.layers.1.ffn.layers.1.bias', 'encoder.layers.1.norms.0.weight', 'encoder.layers.1.norms.0.bias', 'encoder.layers.1.norms.1.weight', 'encoder.layers.1.norms.1.bias', 'encoder.layers.2.self_attn.attn.in_proj_weight', 'encoder.layers.2.self_attn.attn.in_proj_bias', 'encoder.layers.2.self_attn.attn.out_proj.weight', 'encoder.layers.2.self_attn.attn.out_proj.bias', 'encoder.layers.2.ffn.layers.0.0.weight', 'encoder.layers.2.ffn.layers.0.0.bias', 'encoder.layers.2.ffn.layers.1.weight', 'encoder.layers.2.ffn.layers.1.bias', 'encoder.layers.2.norms.0.weight', 'encoder.layers.2.norms.0.bias', 'encoder.layers.2.norms.1.weight', 'encoder.layers.2.norms.1.bias', 'encoder.layers.3.self_attn.attn.in_proj_weight', 'encoder.layers.3.self_attn.attn.in_proj_bias', 'encoder.layers.3.self_attn.attn.out_proj.weight', 'encoder.layers.3.self_attn.attn.out_proj.bias', 'encoder.layers.3.ffn.layers.0.0.weight', 'encoder.layers.3.ffn.layers.0.0.bias', 'encoder.layers.3.ffn.layers.1.weight', 'encoder.layers.3.ffn.layers.1.bias', 'encoder.layers.3.norms.0.weight', 'encoder.layers.3.norms.0.bias', 'encoder.layers.3.norms.1.weight', 'encoder.layers.3.norms.1.bias', 'encoder.layers.4.self_attn.attn.in_proj_weight', 'encoder.layers.4.self_attn.attn.in_proj_bias', 'encoder.layers.4.self_attn.attn.out_proj.weight', 'encoder.layers.4.self_attn.attn.out_proj.bias', 'encoder.layers.4.ffn.layers.0.0.weight', 'encoder.layers.4.ffn.layers.0.0.bias', 'encoder.layers.4.ffn.layers.1.weight', 'encoder.layers.4.ffn.layers.1.bias', 'encoder.layers.4.norms.0.weight', 'encoder.layers.4.norms.0.bias', 'encoder.layers.4.norms.1.weight', 'encoder.layers.4.norms.1.bias', 'encoder.layers.5.self_attn.attn.in_proj_weight', 'encoder.layers.5.self_attn.attn.in_proj_bias', 'encoder.layers.5.self_attn.attn.out_proj.weight', 'encoder.layers.5.self_attn.attn.out_proj.bias', 'encoder.layers.5.ffn.layers.0.0.weight', 'encoder.layers.5.ffn.layers.0.0.bias', 'encoder.layers.5.ffn.layers.1.weight', 'encoder.layers.5.ffn.layers.1.bias', 'encoder.layers.5.norms.0.weight', 'encoder.layers.5.norms.0.bias', 'encoder.layers.5.norms.1.weight', 'encoder.layers.5.norms.1.bias', 'decoder.layers.0.self_attn.attn.in_proj_weight', 'decoder.layers.0.self_attn.attn.in_proj_bias', 'decoder.layers.0.self_attn.attn.out_proj.weight', 'decoder.layers.0.self_attn.attn.out_proj.bias', 'decoder.layers.0.cross_attn.attn.in_proj_weight', 'decoder.layers.0.cross_attn.attn.in_proj_bias', 'decoder.layers.0.cross_attn.attn.out_proj.weight', 'decoder.layers.0.cross_attn.attn.out_proj.bias', 'decoder.layers.0.ffn.layers.0.0.weight', 'decoder.layers.0.ffn.layers.0.0.bias', 'decoder.layers.0.ffn.layers.1.weight', 'decoder.layers.0.ffn.layers.1.bias', 'decoder.layers.0.norms.0.weight', 'decoder.layers.0.norms.0.bias', 'decoder.layers.0.norms.1.weight', 'decoder.layers.0.norms.1.bias', 'decoder.layers.0.norms.2.weight', 'decoder.layers.0.norms.2.bias', 'decoder.layers.1.self_attn.attn.in_proj_weight', 'decoder.layers.1.self_attn.attn.in_proj_bias', 'decoder.layers.1.self_attn.attn.out_proj.weight', 'decoder.layers.1.self_attn.attn.out_proj.bias', 'decoder.layers.1.cross_attn.attn.in_proj_weight', 'decoder.layers.1.cross_attn.attn.in_proj_bias', 'decoder.layers.1.cross_attn.attn.out_proj.weight', 'decoder.layers.1.cross_attn.attn.out_proj.bias', 'decoder.layers.1.ffn.layers.0.0.weight', 'decoder.layers.1.ffn.layers.0.0.bias', 'decoder.layers.1.ffn.layers.1.weight', 'decoder.layers.1.ffn.layers.1.bias', 'decoder.layers.1.norms.0.weight', 'decoder.layers.1.norms.0.bias', 'decoder.layers.1.norms.1.weight', 'decoder.layers.1.norms.1.bias', 'decoder.layers.1.norms.2.weight', 'decoder.layers.1.norms.2.bias', 'decoder.layers.2.self_attn.attn.in_proj_weight', 'decoder.layers.2.self_attn.attn.in_proj_bias', 'decoder.layers.2.self_attn.attn.out_proj.weight', 'decoder.layers.2.self_attn.attn.out_proj.bias', 'decoder.layers.2.cross_attn.attn.in_proj_weight', 'decoder.layers.2.cross_attn.attn.in_proj_bias', 'decoder.layers.2.cross_attn.attn.out_proj.weight', 'decoder.layers.2.cross_attn.attn.out_proj.bias', 'decoder.layers.2.ffn.layers.0.0.weight', 'decoder.layers.2.ffn.layers.0.0.bias', 'decoder.layers.2.ffn.layers.1.weight', 'decoder.layers.2.ffn.layers.1.bias', 'decoder.layers.2.norms.0.weight', 'decoder.layers.2.norms.0.bias', 'decoder.layers.2.norms.1.weight', 'decoder.layers.2.norms.1.bias', 'decoder.layers.2.norms.2.weight', 'decoder.layers.2.norms.2.bias', 'decoder.layers.3.self_attn.attn.in_proj_weight', 'decoder.layers.3.self_attn.attn.in_proj_bias', 'decoder.layers.3.self_attn.attn.out_proj.weight', 'decoder.layers.3.self_attn.attn.out_proj.bias', 'decoder.layers.3.cross_attn.attn.in_proj_weight', 'decoder.layers.3.cross_attn.attn.in_proj_bias', 'decoder.layers.3.cross_attn.attn.out_proj.weight', 'decoder.layers.3.cross_attn.attn.out_proj.bias', 'decoder.layers.3.ffn.layers.0.0.weight', 'decoder.layers.3.ffn.layers.0.0.bias', 'decoder.layers.3.ffn.layers.1.weight', 'decoder.layers.3.ffn.layers.1.bias', 'decoder.layers.3.norms.0.weight', 'decoder.layers.3.norms.0.bias', 'decoder.layers.3.norms.1.weight', 'decoder.layers.3.norms.1.bias', 'decoder.layers.3.norms.2.weight', 'decoder.layers.3.norms.2.bias', 'decoder.layers.4.self_attn.attn.in_proj_weight', 'decoder.layers.4.self_attn.attn.in_proj_bias', 'decoder.layers.4.self_attn.attn.out_proj.weight', 'decoder.layers.4.self_attn.attn.out_proj.bias', 'decoder.layers.4.cross_attn.attn.in_proj_weight', 'decoder.layers.4.cross_attn.attn.in_proj_bias', 'decoder.layers.4.cross_attn.attn.out_proj.weight', 'decoder.layers.4.cross_attn.attn.out_proj.bias', 'decoder.layers.4.ffn.layers.0.0.weight', 'decoder.layers.4.ffn.layers.0.0.bias', 'decoder.layers.4.ffn.layers.1.weight', 'decoder.layers.4.ffn.layers.1.bias', 'decoder.layers.4.norms.0.weight', 'decoder.layers.4.norms.0.bias', 'decoder.layers.4.norms.1.weight', 'decoder.layers.4.norms.1.bias', 'decoder.layers.4.norms.2.weight', 'decoder.layers.4.norms.2.bias', 'decoder.layers.5.self_attn.attn.in_proj_weight', 'decoder.layers.5.self_attn.attn.in_proj_bias', 'decoder.layers.5.self_attn.attn.out_proj.weight', 'decoder.layers.5.self_attn.attn.out_proj.bias', 'decoder.layers.5.cross_attn.attn.in_proj_weight', 'decoder.layers.5.cross_attn.attn.in_proj_bias', 'decoder.layers.5.cross_attn.attn.out_proj.weight', 'decoder.layers.5.cross_attn.attn.out_proj.bias', 'decoder.layers.5.ffn.layers.0.0.weight', 'decoder.layers.5.ffn.layers.0.0.bias', 'decoder.layers.5.ffn.layers.1.weight', 'decoder.layers.5.ffn.layers.1.bias', 'decoder.layers.5.norms.0.weight', 'decoder.layers.5.norms.0.bias', 'decoder.layers.5.norms.1.weight', 'decoder.layers.5.norms.1.bias', 'decoder.layers.5.norms.2.weight', 'decoder.layers.5.norms.2.bias', 'decoder.post_norm.weight', 'decoder.post_norm.bias', 'query_embedding.weight']\n"
     ]
    }
   ],
   "source": [
    "PATH_CHECKPOINT_FILE = \"C:/Users/Username/source/repos/mmdetection/checkpoints/detr_r50_8xb2-150e_coco_20221023_153551-436d03e8.pth\"\n",
    "\n",
    "state_dict, keys = get_model_state_dict_and_keys(PATH_CHECKPOINT_FILE)\n",
    "\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute single wise ablations on the component of a checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 0 in the tensor after ablation: 5.00%\n"
     ]
    }
   ],
   "source": [
    "PATH_CHECKPOINT_FILE = \"C:/Users/Username/source/repos/mmdetection/checkpoints/detr_r50_8xb2-150e_coco_20221023_153551-436d03e8.pth\"\n",
    "\n",
    "compute_single_wise_ablations_percentage(\n",
    "    PATH_CHECKPOINT_FILE, \n",
    "    5, \n",
    "    'query_embedding.weight', \n",
    "    number_of_ablations=1, \n",
    "    PATH_SAVE_DIR='')\n",
    "\n",
    "PATH_CHECKPOINT_FILE = \"model_query_embedding.weight_single_wise_5_0.pth\"\n",
    "\n",
    "state_dict, keys = get_model_state_dict_and_keys(PATH_CHECKPOINT_FILE)\n",
    "print(f\"Percentage of 0 in the tensor after ablation: {((state_dict['query_embedding.weight'] == 0).sum().item() / state_dict['query_embedding.weight'].numel()) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute attention head ablations on the component of a checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 / 1\n",
      "tensor([[-0.0120,  0.0555, -0.1245,  ...,  0.0226,  0.0327,  0.0485],\n",
      "        [-0.1808, -0.2857, -0.0591,  ..., -0.1256, -0.0149, -0.0451],\n",
      "        [ 0.0451, -0.0790,  0.0445,  ..., -0.0432, -0.0204, -0.0143],\n",
      "        ...,\n",
      "        [-0.0510, -0.0797,  0.0507,  ..., -0.0167, -0.0619, -0.0018],\n",
      "        [-0.0689, -0.0375,  0.0599,  ...,  0.0542,  0.0083, -0.0093],\n",
      "        [ 0.0647,  0.0025,  0.0155,  ..., -0.0861,  0.0116,  0.0414]])\n",
      "Percentage of 0 in the tensor after ablation: 5.00%\n"
     ]
    }
   ],
   "source": [
    "PATH_CHECKPOINT_FILE = \"C:/Users/Username/source/repos/mmdetection/checkpoints/detr_r50_8xb2-150e_coco_20221023_153551-436d03e8.pth\"\n",
    "\n",
    "compute_attention_head_detr_ablations_percentage(\n",
    "    PATH_CHECKPOINT_FILE,\n",
    "    ablation_percentage=5,\n",
    "    ablation_component_template=\"encoder.layers.{layer}.self_attn.attn.in_proj_weight\",\n",
    "    layers_to_ablate=range(6),\n",
    "    number_of_ablations=1,\n",
    "    PATH_SAVE_DIR='')\n",
    "\n",
    "PATH_CHECKPOINT_FILE = \"model_encoder.layers.self_attn.attn.in_proj_weight_attention_head_5_0.pth\"\n",
    "\n",
    "state_dict, keys = get_model_state_dict_and_keys(PATH_CHECKPOINT_FILE)\n",
    "print(state_dict['encoder.layers.0.self_attn.attn.in_proj_weight'])\n",
    "print(f\"Percentage of 0 in the tensor after ablation: {((state_dict['encoder.layers.0.self_attn.attn.in_proj_weight'] == 0).sum().item() / state_dict['encoder.layers.0.self_attn.attn.in_proj_weight'].numel()) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute full component ablations on the component of a checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0120,  0.0555, -0.1245,  ...,  0.0226,  0.0327,  0.0485],\n",
      "        [-0.1808, -0.2857, -0.0591,  ..., -0.1256, -0.0149, -0.0451],\n",
      "        [ 0.0451, -0.0790,  0.0445,  ..., -0.0432, -0.0204, -0.0143],\n",
      "        ...,\n",
      "        [-0.0510, -0.0797,  0.0507,  ..., -0.0167, -0.0619, -0.0018],\n",
      "        [-0.0689, -0.0375,  0.0599,  ...,  0.0542,  0.0083, -0.0093],\n",
      "        [ 0.0647,  0.0025,  0.0155,  ..., -0.0861,  0.0116,  0.0414]])\n"
     ]
    }
   ],
   "source": [
    "PATH_CHECKPOINT_FILE = \"C:/Users/Username/source/repos/mmdetection/checkpoints/detr_r50_8xb2-150e_coco_20221023_153551-436d03e8.pth\"\n",
    "\n",
    "compute_component_wise_complete_ablations(\n",
    "        PATH_CHECKPOINT_FILE,\n",
    "        'query_embedding.weight',\n",
    "        PATH_SAVE_DIR='')\n",
    "\n",
    "PATH_CHECKPOINT_FILE = \"model_query_embedding.weight_component_wise.pth\"\n",
    "\n",
    "state_dict, keys = get_model_state_dict_and_keys(PATH_CHECKPOINT_FILE)\n",
    "print(state_dict['query_embedding.weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute full component ablations cumulative on the layers progressively on the component of a checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "PATH_CHECKPOINT_FILE = \"C:/Users/Username/source/repos/mmdetection/checkpoints/detr_r50_8xb2-150e_coco_20221023_153551-436d03e8.pth\"\n",
    "\n",
    "compute_progressive_component_ablations(\n",
    "        PATH_CHECKPOINT_FILE,\n",
    "        base_component_path=\"encoder.layers\",\n",
    "        component_to_ablate=\"self_attn.attn.in_proj_weight\",\n",
    "        PATH_SAVE_DIR='')\n",
    "\n",
    "PATH_CHECKPOINT_FILE = \"model_encoder.layers_0_self_attn.attn.in_proj_weight_component_layers.pth\"\n",
    "\n",
    "state_dict, keys = get_model_state_dict_and_keys(PATH_CHECKPOINT_FILE)\n",
    "print(state_dict['encoder.layers.0.self_attn.attn.in_proj_weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the inference with the ablated model and integrate the ground truth from the annotation file into the mmdetection data structure for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: query_embedding_5/model_query_embedding.weight_single_wise_5_0.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "components = [\n",
    "    \"query_embedding_5\"\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"model_query_embedding.weight_single_wise_5_\"\n",
    "]\n",
    "\n",
    "PATH_CONFIG_FILE = \"C:/Users/Username/source/repos/mmdetection/configs/detr/detr_r50_8xb2-150e_coco.py\"\n",
    "PATH_ANNOTATIONS = \"C:/Users/Username/coco/annotations/instances_val2017.json\"\n",
    "PATH_IMG = \"C:/Users/Username/coco/val2017/\"\n",
    "PATHS_FULL = glob.glob(f\"{PATH_IMG}/*.jpg\")\n",
    "\n",
    "for component, name in zip(components, names):\n",
    "    PICKLE_SAVE_DIR = \"\" + component + \"/\"\n",
    "    \n",
    "    for i in range(0, 1):\n",
    "        checkpoint_file = \"\" + component + f\"/{name}{i}.pth\"\n",
    "        save_with_pickle = run_inference_and_integrate_ground_truth(PATH_CONFIG_FILE, checkpoint_file, PATH_ANNOTATIONS, PATHS_FULL, device=\"cuda:0\")\n",
    "        \n",
    "        pickle_file_path = os.path.join(PICKLE_SAVE_DIR, f'igt_' + component + f'_{i}.pkl')\n",
    "        \n",
    "        with open(pickle_file_path, 'wb') as f:\n",
    "            pickle.dump(save_with_pickle, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Results F1 Score and GIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of bbox_regression_gt_pred_average_giou_overall_result_0.json:\n",
      "{\n",
      "    \"average_giou\": 0.6987570316070275\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Content of bbox_regression_gt_pred_average_giou_per_class_result_0.json:\n",
      "{\n",
      "    \"person\": 0.7476506753222205,\n",
      "    \"bicycle\": 0.7010570925512657,\n",
      "    \"car\": 0.6734313731726705,\n",
      "    \"motorcycle\": 0.7712092707460781,\n",
      "    \"airplane\": 0.8577881830972323,\n",
      "    \"bus\": 0.8592777720186859,\n",
      "    \"train\": 0.8916712030302734,\n",
      "    \"truck\": 0.8040049842184805,\n",
      "    \"boat\": 0.6245417962204385,\n",
      "    \"traffic light\": 0.5733728508951041,\n",
      "    \"fire hydrant\": 0.8685669191591032,\n",
      "    \"stop sign\": 0.8197764247211058,\n",
      "    \"parking meter\": 0.8683688505774453,\n",
      "    \"bench\": 0.6816297105616321,\n",
      "    \"bird\": 0.6018998203795802,\n",
      "    \"cat\": 0.9309773120317566,\n",
      "    \"dog\": 0.9176147644361738,\n",
      "    \"horse\": 0.8362198552080229,\n",
      "    \"sheep\": 0.7935930527746677,\n",
      "    \"cow\": 0.7917165620374543,\n",
      "    \"elephant\": 0.8692282050016866,\n",
      "    \"bear\": 0.9439598492213658,\n",
      "    \"zebra\": 0.8756962000651467,\n",
      "    \"giraffe\": 0.878406212122544,\n",
      "    \"backpack\": 0.6982791843616591,\n",
      "    \"umbrella\": 0.735356069311048,\n",
      "    \"handbag\": 0.6350515614572267,\n",
      "    \"tie\": 0.703551324111396,\n",
      "    \"suitcase\": 0.7321636475166496,\n",
      "    \"frisbee\": 0.8342623549671668,\n",
      "    \"skis\": 0.6363983542549839,\n",
      "    \"snowboard\": 0.8449235942802931,\n",
      "    \"sports ball\": 0.6696040488345206,\n",
      "    \"kite\": 0.6713242870711563,\n",
      "    \"baseball bat\": 0.702736567889312,\n",
      "    \"baseball glove\": 0.6837862258957278,\n",
      "    \"skateboard\": 0.7933753962378677,\n",
      "    \"surfboard\": 0.7694287824991572,\n",
      "    \"tennis racket\": 0.7939092829751159,\n",
      "    \"bottle\": 0.7010867345938568,\n",
      "    \"wine glass\": 0.6978044728149517,\n",
      "    \"cup\": 0.7370163932919301,\n",
      "    \"fork\": 0.7633531985216235,\n",
      "    \"knife\": 0.6043981374467461,\n",
      "    \"spoon\": 0.6689758007414639,\n",
      "    \"bowl\": 0.7993150349764749,\n",
      "    \"banana\": 0.6515775047874416,\n",
      "    \"apple\": 0.632227648236898,\n",
      "    \"sandwich\": 0.8281965558143223,\n",
      "    \"orange\": 0.7627847228067541,\n",
      "    \"broccoli\": 0.6977281062801679,\n",
      "    \"carrot\": 0.6266664075572329,\n",
      "    \"hot dog\": 0.7086907208498036,\n",
      "    \"pizza\": 0.8141493348138673,\n",
      "    \"donut\": 0.6988572138165378,\n",
      "    \"cake\": 0.7428995866175001,\n",
      "    \"chair\": 0.6686852625842272,\n",
      "    \"couch\": 0.902002241644826,\n",
      "    \"potted plant\": 0.7044026774013101,\n",
      "    \"bed\": 0.9048581532577971,\n",
      "    \"dining table\": 0.8048084589146208,\n",
      "    \"toilet\": 0.8958410524107792,\n",
      "    \"tv\": 0.8425562735418884,\n",
      "    \"laptop\": 0.884086883884702,\n",
      "    \"mouse\": 0.7718852201574727,\n",
      "    \"remote\": 0.6703461003471091,\n",
      "    \"keyboard\": 0.8349692155333126,\n",
      "    \"cell phone\": 0.7101104155643493,\n",
      "    \"microwave\": 0.8172091234188813,\n",
      "    \"oven\": 0.8300860296556,\n",
      "    \"toaster\": 0.8552856594324112,\n",
      "    \"sink\": 0.7560138927840199,\n",
      "    \"refrigerator\": 0.892231674970321,\n",
      "    \"book\": 0.5421165534595214,\n",
      "    \"clock\": 0.7764872182543876,\n",
      "    \"vase\": 0.7492392340197636,\n",
      "    \"scissors\": 0.8270282196998596,\n",
      "    \"teddy bear\": 0.8093654083236594,\n",
      "    \"hair drier\": 0.5215137675404549,\n",
      "    \"toothbrush\": 0.6814905296011669\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Content of f1_score_classification_overall_result_0.json:\n",
      "{\n",
      "    \"Overall_F1_Score\": 0.8526141567301203\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Content of f1_score_classification_per_class_result_0.json:\n",
      "{\n",
      "    \"person\": 0.947642802570671,\n",
      "    \"bicycle\": 0.8770226537216829,\n",
      "    \"car\": 0.8321400159108991,\n",
      "    \"motorcycle\": 0.8724279835390947,\n",
      "    \"airplane\": 0.9185667752442997,\n",
      "    \"bus\": 0.6918918918918919,\n",
      "    \"train\": 0.792079207920792,\n",
      "    \"truck\": 0.48705656759348037,\n",
      "    \"boat\": 0.8946188340807175,\n",
      "    \"traffic light\": 0.9322448979591837,\n",
      "    \"fire hydrant\": 0.91,\n",
      "    \"stop sign\": 0.8993288590604026,\n",
      "    \"parking meter\": 0.7567567567567567,\n",
      "    \"bench\": 0.6968325791855203,\n",
      "    \"bird\": 0.8706467661691542,\n",
      "    \"cat\": 0.8811881188118812,\n",
      "    \"dog\": 0.817155756207675,\n",
      "    \"horse\": 0.925589836660617,\n",
      "    \"sheep\": 0.92816091954023,\n",
      "    \"cow\": 0.9128738621586475,\n",
      "    \"elephant\": 0.9653846153846153,\n",
      "    \"bear\": 0.875,\n",
      "    \"zebra\": 0.9708029197080291,\n",
      "    \"giraffe\": 0.989247311827957,\n",
      "    \"backpack\": 0.5778443113772455,\n",
      "    \"umbrella\": 0.8853658536585366,\n",
      "    \"handbag\": 0.6266666666666667,\n",
      "    \"tie\": 0.8771186440677966,\n",
      "    \"suitcase\": 0.8045977011494253,\n",
      "    \"frisbee\": 0.9380530973451328,\n",
      "    \"skis\": 0.8792079207920792,\n",
      "    \"snowboard\": 0.6785714285714286,\n",
      "    \"sports ball\": 0.8693957115009747,\n",
      "    \"kite\": 0.9366715758468336,\n",
      "    \"baseball bat\": 0.9072164948453607,\n",
      "    \"baseball glove\": 0.8671328671328672,\n",
      "    \"skateboard\": 0.923943661971831,\n",
      "    \"surfboard\": 0.8660194174757282,\n",
      "    \"tennis racket\": 0.9175946547884187,\n",
      "    \"bottle\": 0.850597609561753,\n",
      "    \"wine glass\": 0.7392638036809815,\n",
      "    \"cup\": 0.6875,\n",
      "    \"fork\": 0.7004608294930875,\n",
      "    \"knife\": 0.67986798679868,\n",
      "    \"spoon\": 0.6180257510729614,\n",
      "    \"bowl\": 0.6871637202152191,\n",
      "    \"banana\": 0.9047619047619048,\n",
      "    \"apple\": 0.7698924731182796,\n",
      "    \"sandwich\": 0.6071428571428571,\n",
      "    \"orange\": 0.7674418604651162,\n",
      "    \"broccoli\": 0.9389671361502347,\n",
      "    \"carrot\": 0.9068150208623088,\n",
      "    \"hot dog\": 0.6222222222222222,\n",
      "    \"pizza\": 0.8860759493670887,\n",
      "    \"donut\": 0.8285714285714286,\n",
      "    \"cake\": 0.7489481065918653,\n",
      "    \"chair\": 0.7829977628635346,\n",
      "    \"couch\": 0.5315985130111524,\n",
      "    \"potted plant\": 0.8644793152639085,\n",
      "    \"bed\": 0.7745664739884394,\n",
      "    \"dining table\": 0.7201516108654453,\n",
      "    \"toilet\": 0.9230769230769231,\n",
      "    \"tv\": 0.8085808580858086,\n",
      "    \"laptop\": 0.774617067833698,\n",
      "    \"mouse\": 0.9223300970873787,\n",
      "    \"remote\": 0.8601036269430052,\n",
      "    \"keyboard\": 0.9066666666666665,\n",
      "    \"cell phone\": 0.7670103092783506,\n",
      "    \"microwave\": 0.5360824742268041,\n",
      "    \"oven\": 0.7306501547987616,\n",
      "    \"toaster\": 0.6956521739130435,\n",
      "    \"sink\": 0.8832951945080091,\n",
      "    \"refrigerator\": 0.8249027237354086,\n",
      "    \"book\": 0.9040852575488455,\n",
      "    \"clock\": 0.9152542372881356,\n",
      "    \"vase\": 0.7184115523465703,\n",
      "    \"scissors\": 0.684931506849315,\n",
      "    \"teddy bear\": 0.8534031413612565,\n",
      "    \"hair drier\": 0.7272727272727273,\n",
      "    \"toothbrush\": 0.7961165048543689\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_paths = [\n",
    "    'query_embedding_5/igt_query_embedding_5_'\n",
    "]\n",
    "\n",
    "output_paths = [\n",
    "    'query_embedding_5/'\n",
    "]\n",
    "\n",
    "for input_path, output_path in zip(input_paths, output_paths):\n",
    "    calculate_average_giou_overall_and_save_results(input_path, output_path, 1, 0)\n",
    "    calculate_average_giou_per_class_and_save_results(input_path, output_path, 1, 0)\n",
    "    calculate_average_f1_score_overall_and_save_results(input_path, output_path, 1, 0)\n",
    "    calculate_average_f1_score_per_class_and_save_results(input_path, output_path, 1, 0)\n",
    "\n",
    "json_files = [\n",
    "    'bbox_regression_gt_pred_average_giou_overall_result_0.json',\n",
    "    'bbox_regression_gt_pred_average_giou_per_class_result_0.json',\n",
    "    'f1_score_classification_overall_result_0.json',\n",
    "    'f1_score_classification_per_class_result_0.json'\n",
    "]\n",
    "\n",
    "for path in output_paths:\n",
    "    for file in json_files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                print(f\"Content of {file}:\")\n",
    "                print(json.dumps(data, indent=4))\n",
    "                print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON in file: {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
